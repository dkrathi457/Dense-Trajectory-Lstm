{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import os.path\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from pandas import Series\n",
    "import time\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "        filepath='/home/cis/Desktop/LStm Dense Trajectories/data/checkpoints/' + 'dt'+ \\\n",
    "            '.{epoch:03d}-{val_loss:.3f}.hdf5',\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tb = TensorBoard(log_dir='/home/cis/Desktop/LStm Dense Trajectories/data/logs')\n",
    "\n",
    "# Helper: Stop when we stop learning.\n",
    "early_stopper = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper: Save results.\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger('/home/cis/Desktop/LStm Dense Trajectories/data/logs/'+ '-' + 'training-dt' + \\\n",
    "        str(timestamp) + '.log')\n",
    "\n",
    "\n",
    "filepath = \"/home/cis/Desktop/LStm Dense Trajectories/training.txt\"\n",
    "training_data_list = pd.read_csv(filepath, sep=\" \", header=None)\n",
    "\n",
    "\n",
    "filepath_test = \"/home/cis/Desktop/LStm Dense Trajectories/testingdata.txt\"\n",
    "testing_data_list = pd.read_csv(filepath_test, sep=\" \", header=None)\n",
    "\n",
    "test_train_list = pd.concat([training_data_list, testing_data_list])\n",
    "\n",
    "classes = ['boxing' , 'handclapping' , 'handwaving' , 'jogging' , 'running' , 'walking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get label from file name and convert to categorical\n",
    "    \n",
    "def make_label_data(file_name, classes):\n",
    "    label = file_name.split(\"_\")\n",
    "    label = label[1]\n",
    "    label_encoded = classes.index(label)\n",
    "    get_label = np_utils.to_categorical (label_encoded, len(classes))       \n",
    "    get_label  = get_label[0]\n",
    "    return get_label\n",
    "\n",
    "\n",
    "def get_size(alldata):\n",
    "    seq_size = []\n",
    "    for i in range(0, len(alldata)):\n",
    "        filename = alldata[i][0]\n",
    "        #print filename\n",
    "        filepath_file = os.path.join(\"/home/cis/Desktop/LStm Dense Trajectories/Dense Trajectories\" , filename)\n",
    "        x= pd.read_csv(filepath_file, sep = \"\\t\", header =None)\n",
    "        size = len(x)\n",
    "        seq_size.append(size)\n",
    "    return seq_size\n",
    "\n",
    "\n",
    "def get_min_value(test_train_list):\n",
    "    print \"Getting Sequence size\"\n",
    "    seq_size = get_size(test_train_list)\n",
    "    print \"Getting Minimum value\"\n",
    "    minvalue = seq_size[0]\n",
    "    \n",
    "    for i in range(0, len(seq_size)):\n",
    "        if seq_size[i] < minvalue:\n",
    "            minvalue = seq_size[i]\n",
    "        else:\n",
    "            minvalue = minvalue\n",
    "    return minvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the training data and labels for the file\n",
    "\n",
    "def load_training_data(training_data_list, classes, minvalue):\n",
    "    X, Y = [],[]\n",
    "    for i in range(0, len(training_data_list)):\n",
    "        filename = training_data_list.iloc[i][0]\n",
    "        #print filename\n",
    "        filepath_file = os.path.join(\"/home/cis/Desktop/LStm Dense Trajectories/Dense Trajectories\" , filename)\n",
    "        x= pd.read_csv(filepath_file, sep = \"\\t\", header =None)\n",
    "        x = x.iloc[:,10:436]\n",
    "        x_sample = x.iloc[random.sample(x.index, minvalue)] \n",
    "        x_sample.sort_index(inplace=True)\n",
    "        x = x_sample.values\n",
    "        label = make_label_data(filename, classes)\n",
    "        X.append(x)\n",
    "        Y.append(label)\n",
    "        ## get label\n",
    "    return np.array(X), np.array(Y)    \n",
    "\n",
    "## Load the testing data and labels\n",
    "\n",
    "def load_testing_data(testing_data_list, classes, minvalue):\n",
    "    X, Y = [],[]\n",
    "    for i in range(0, len(testing_data_list)):\n",
    "        filename = testing_data_list.iloc[i][0]\n",
    "        #print filename\n",
    "        filepath_file = os.path.join(\"/home/cis/Desktop/LStm Dense Trajectories/Dense Trajectories\" , filename)\n",
    "        x= pd.read_csv(filepath_file, sep = \"\\t\", header =None)\n",
    "        x = x.iloc[:,10:436]\n",
    "        x_sample = x.iloc[random.sample(x.index, minvalue)] \n",
    "        x_sample.sort_index(inplace=True)\n",
    "        x = x_sample.values\n",
    "        label = make_label_data(filename, classes)\n",
    "        X.append(x)\n",
    "        Y.append(label)\n",
    "        ## get label\n",
    "    return np.array(X), np.array(Y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minvalue = get_min_value(test_train_list.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = load_training_data(training_data_list, classes, minvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test , Y_test = load_testing_data(testing_data_list, classes, minvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer= optimizer,\n",
    "                           metrics = ['accuracy'] )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_test, Y_test), verbose=1, callbacks=[checkpointer, tb, early_stopper, csv_logger])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
